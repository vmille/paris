******** Limited places ********
Be nice, if you can not attend, please release your slot.

Register only if your a physically attending

Your name will be ask when you arrive (security reason).

Fifty-eighth edition of C++ French User Group (C++Frug) Paris. This session will be hybrid:

- MUREX welcomes us, 15 Boulevard de l'Amiral Bruix, Paris 75016 (Metro 1, Tram T3, RER C, RER E, exit Porte Maillot)
- Video will be shared online on Discord

Before starting, please join our Discords (https://discord.gg/tjx9bFpBfC & https://discord.gg/9aU6tZabJV). Discord desktop application is more stable than web one.

Here is the program (Paris time):

- 19h00 Welcome
- 19h15 News of the C++ ecosystem
- 19h20 Heaps Don't Lie - Guidelines for Memory Allocation in C++ -- Mathieu Ropert
- 20h20 Snacks & drinks
- 21h20 The CUDA C++ Developer's Toolbox -- Bryce Adelstein Lelbach

If you are interested to talk, please MP or contact us on Discord.

-------------------

**Heaps Don't Lie** - Guidelines for Memory Allocation in C++
Dynamic memory allocations are ever-present in most programs. A simple look at the RAM usage of the browser you are currently using to read this abstract will likely tell you something. But what of the runtime performance cost? How much (or little) should you be concerned about it and keep it in mind while implementing new features or designing software? In this talk, we will present a set of about 10 guidelines to keep in mind when dealing with dynamic memory allocation and mitigate its potential performance impact on execution speed. From quite simple to somewhat advanced, everyone should be able to walk away from this talk having learnt something.

**Mathieu Ropert**
French C++ expert working on (somewhat) historical video games. Decided to upgrade his compiler once and has been blogging about build systems ever since. Past speaker at CppCon, Meeting C++ and ACCU. Used to run the Paris C++ User Group. Currently lives in Sweden.

-------------------

**The CUDA C++ Developer's Toolbox**
Getting the most out of your GPU with C++ doesn't require writing custom kernels or manually managing storage for everything! Come learn about the libraries and techniques that make writing CUDA C++ code easier and more performant. Through examples, we'll explore all aspects of writing modern C++ software for GPUs, including heterogeneous memory management, algorithm design, and synchronization.

During this talk, you'll:
- Learn to evaluate when you should use a CUDA library versus writing your own kernel.
- Explore popular CUDA C++ libraries such as Thrust, CUB, and libcu++.
- Understand how you can easily compose different CUDA libraries and your own custom CUDA C++ code together.
- Build intuition about the performance implications of CUDA libraries.
- You'll leave confident about how to select the best tool for the job to accelerate your C++ applications for your unique use cases.

**Bryce Adelstein Lelbach**
has spent over a decade developing programming languages, compilers, and software libraries. He is passionate about parallel programming and strives to make it more accessible for everyone.
Bryce is a Principal Architect at NVIDIA, where he leads programming language efforts and drives the technical roadmap for NVIDIA's compute compilers and libraries.
He is one of the leaders of the systems programming language community, having served as chair of the Standard C++ Library Evolution group and the US standards committee for programming languages (INCITS/PL22). He has been an organizer and program chair for many conferences over the years.
On the C++ Committee, he has personally worked on concurrency primitives, parallel algorithms, executors, and multidimensional arrays. He is one of the founding developers of the HPX parallel runtime system.
Outside of work, Bryce is passionate about airplanes and watches. He lives in Midtown Manhattan with his girlfriend and dog.